{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3722da24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ta-lib\n",
      "  Downloading ta_lib-0.6.5-cp312-cp312-win_amd64.whl.metadata (24 kB)\n",
      "Collecting build (from ta-lib)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: numpy in f:\\anaconda\\lib\\site-packages (from ta-lib) (1.26.4)\n",
      "Requirement already satisfied: pip in f:\\anaconda\\lib\\site-packages (from ta-lib) (24.0)\n",
      "Requirement already satisfied: packaging>=19.1 in f:\\anaconda\\lib\\site-packages (from build->ta-lib) (23.2)\n",
      "Collecting pyproject_hooks (from build->ta-lib)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: colorama in f:\\anaconda\\lib\\site-packages (from build->ta-lib) (0.4.6)\n",
      "Downloading ta_lib-0.6.5-cp312-cp312-win_amd64.whl (883 kB)\n",
      "   ---------------------------------------- 0.0/883.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 20.5/883.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 61.4/883.4 kB 825.8 kB/s eta 0:00:01\n",
      "   ---- --------------------------------- 102.4/883.4 kB 845.5 kB/s eta 0:00:01\n",
      "   ------ --------------------------------- 153.6/883.4 kB 1.0 MB/s eta 0:00:01\n",
      "   --------- ---------------------------- 215.0/883.4 kB 939.4 kB/s eta 0:00:01\n",
      "   ------------ --------------------------- 286.7/883.4 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 368.6/883.4 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 542.7/883.4 kB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 542.7/883.4 kB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 542.7/883.4 kB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 819.2/883.4 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/883.4 kB 1.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- 883.4/883.4 kB 465.7 kB/s eta 0:00:00\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: pyproject_hooks, build, ta-lib\n",
      "Successfully installed build-1.3.0 pyproject_hooks-1.2.0 ta-lib-0.6.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at f:\\anaconda\\lib\\site-packages\\ibapi-10.33.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install ta-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda8a992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Open Interest</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-25T15:15:00+05:30</td>\n",
       "      <td>2552.6</td>\n",
       "      <td>2552.8</td>\n",
       "      <td>2545.0</td>\n",
       "      <td>2549.5</td>\n",
       "      <td>47654</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-25T15:00:00+05:30</td>\n",
       "      <td>2549.7</td>\n",
       "      <td>2552.9</td>\n",
       "      <td>2544.1</td>\n",
       "      <td>2552.7</td>\n",
       "      <td>31219</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-25T14:45:00+05:30</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>2551.5</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>2549.7</td>\n",
       "      <td>12152</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-25T14:30:00+05:30</td>\n",
       "      <td>2550.6</td>\n",
       "      <td>2553.0</td>\n",
       "      <td>2547.2</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>5457</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-25T14:15:00+05:30</td>\n",
       "      <td>2549.2</td>\n",
       "      <td>2553.8</td>\n",
       "      <td>2546.7</td>\n",
       "      <td>2550.8</td>\n",
       "      <td>11238</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp    open    high     low   close  volume  \\\n",
       "0  2025-07-25T15:15:00+05:30  2552.6  2552.8  2545.0  2549.5   47654   \n",
       "1  2025-07-25T15:00:00+05:30  2549.7  2552.9  2544.1  2552.7   31219   \n",
       "2  2025-07-25T14:45:00+05:30  2550.0  2551.5  2546.0  2549.7   12152   \n",
       "3  2025-07-25T14:30:00+05:30  2550.6  2553.0  2547.2  2550.0    5457   \n",
       "4  2025-07-25T14:15:00+05:30  2549.2  2553.8  2546.7  2550.8   11238   \n",
       "\n",
       "   Open Interest    symbol  \n",
       "0              0  ADANIENT  \n",
       "1              0  ADANIENT  \n",
       "2              0  ADANIENT  \n",
       "3              0  ADANIENT  \n",
       "4              0  ADANIENT  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('all_stocks_ohlc.csv')\n",
    "data.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaaf90bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Open Interest</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-07-25  15:15:00</td>\n",
       "      <td>2552.6</td>\n",
       "      <td>2552.8</td>\n",
       "      <td>2545.0</td>\n",
       "      <td>2549.5</td>\n",
       "      <td>47654</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-07-25  15:00:00</td>\n",
       "      <td>2549.7</td>\n",
       "      <td>2552.9</td>\n",
       "      <td>2544.1</td>\n",
       "      <td>2552.7</td>\n",
       "      <td>31219</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-25  14:45:00</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>2551.5</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>2549.7</td>\n",
       "      <td>12152</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-25  14:30:00</td>\n",
       "      <td>2550.6</td>\n",
       "      <td>2553.0</td>\n",
       "      <td>2547.2</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>5457</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-07-25  14:15:00</td>\n",
       "      <td>2549.2</td>\n",
       "      <td>2553.8</td>\n",
       "      <td>2546.7</td>\n",
       "      <td>2550.8</td>\n",
       "      <td>11238</td>\n",
       "      <td>0</td>\n",
       "      <td>ADANIENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp    open    high     low   close  volume  \\\n",
       "0  2025-07-25  15:15:00  2552.6  2552.8  2545.0  2549.5   47654   \n",
       "1  2025-07-25  15:00:00  2549.7  2552.9  2544.1  2552.7   31219   \n",
       "2  2025-07-25  14:45:00  2550.0  2551.5  2546.0  2549.7   12152   \n",
       "3  2025-07-25  14:30:00  2550.6  2553.0  2547.2  2550.0    5457   \n",
       "4  2025-07-25  14:15:00  2549.2  2553.8  2546.7  2550.8   11238   \n",
       "\n",
       "   Open Interest    symbol  \n",
       "0              0  ADANIENT  \n",
       "1              0  ADANIENT  \n",
       "2              0  ADANIENT  \n",
       "3              0  ADANIENT  \n",
       "4              0  ADANIENT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data ['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data['timestamp'] = data['timestamp'].dt.strftime('%Y-%m-%d  %H:%M:%S')\n",
    "data.head()  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b89028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the daily closing candles at 15:15:00\n",
    "# Adjust time depending on your exact last candle time in your data\n",
    "closing_time = pd.to_datetime(\"15:15:00\").time()\n",
    "daily_close_df = data[data['timestamp'] == closing_time].copy()\n",
    "\n",
    "# Sort by symbol and date\n",
    "daily_close_df = daily_close_df.sort_values(['symbol', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "results = []\n",
    "symbols = daily_close_df['symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a0125",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2388\\3396363271.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('symbol', group_keys=False).apply(add_rsi).reset_index(drop=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2388\\3396363271.py:54: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  eod_rsi = df.groupby(['symbol', 'date'], group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trades: 0\n",
      "âš  No trades generated â€” conditions likely too strict.\n",
      "No trades generated â€” backtest summary skipped.\n",
      "Total Trades: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pnl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 155\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trades generated â€” backtest summary skipped.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Trades:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(results_df))\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal PnL:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpnl\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of trades found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# Optional: Save results\u001b[39;00m\n",
      "File \u001b[1;32mf:\\anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mf:\\anaconda\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pnl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"all_stocks_ohlc.csv\", parse_dates=['timestamp'])\n",
    "\n",
    "# Ensure columns are lowercase\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "# Sort for safety\n",
    "df.sort_values(by=['timestamp', 'symbol'], inplace=True)\n",
    "\n",
    "# --- STEP 1: Add RSI and aggregate data ---\n",
    "def add_rsi(data):\n",
    "    data['rsi'] = talib.RSI(data['close'], timeperiod=14)\n",
    "    return data\n",
    "\n",
    "df = df.groupby('symbol', group_keys=False).apply(add_rsi).reset_index(drop=True)\n",
    "\n",
    "# Convert timestamp to datetime and extract date\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['time'] = df['timestamp'].dt.time\n",
    "\n",
    "# Daily aggregations\n",
    "daily = df.groupby(['symbol', 'date']).agg({\n",
    "    'open': 'first',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last',\n",
    "    'volume': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Weekly high\n",
    "weekly_high = daily.groupby('symbol').rolling(window=5, on='date')['high'].max().reset_index()\n",
    "weekly_high.rename(columns={'high': 'weekly_high'}, inplace=True)\n",
    "daily = daily.merge(weekly_high[['symbol', 'date', 'weekly_high']], on=['symbol', 'date'], how='left')\n",
    "\n",
    "# Previous day high\n",
    "daily['prev_day_high'] = daily.groupby('symbol')['high'].shift(1)\n",
    "\n",
    "# 5-day average volume\n",
    "daily['avg_5_vol'] = daily.groupby('symbol')['volume'].rolling(window=5).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# --- STEP 2: Generate Buy Signals (EOD) ---\n",
    "daily['signal'] = (\n",
    "    (daily['volume'] > 1.5 * daily['avg_5_vol']) &\n",
    "    (daily['close'] > daily['prev_day_high']) &\n",
    "    (daily['close'] > daily['weekly_high'])\n",
    ")\n",
    "\n",
    "# For RSI, use 5-min df on daily EOD\n",
    "eod_rsi = df.groupby(['symbol', 'date'], group_keys=False).apply(\n",
    "    lambda x: (x['rsi'].iloc[-1] > 70) and (x['rsi'] > 70).any()\n",
    ").reset_index().rename(columns={0: 'rsi_signal'})\n",
    "\n",
    "\n",
    "daily = daily.merge(eod_rsi, on=['symbol', 'date'], how='left')\n",
    "daily['final_signal'] = daily['signal'] & daily['rsi_signal']\n",
    "\n",
    "# --- STEP 3: Execute Next Day Trade ---\n",
    "results = []\n",
    "\n",
    "for idx, row in daily.iterrows():\n",
    "    if not row['final_signal']:\n",
    "        continue\n",
    "\n",
    "    symbol = row['symbol']\n",
    "    signal_date = pd.to_datetime(row['date'])\n",
    "    next_day = signal_date + timedelta(days=1)\n",
    "\n",
    "    # Get next day's data\n",
    "    next_day_data = df[(df['symbol'] == symbol) & (df['timestamp'].dt.date == next_day.date())]\n",
    "    \n",
    "    # Get 9:15 to 9:30 candle\n",
    "    candle = next_day_data[\n",
    "        (next_day_data['timestamp'].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "        (next_day_data['timestamp'].dt.time <= pd.to_datetime(\"09:30\").time())\n",
    "    ]\n",
    "\n",
    "    if candle.empty:\n",
    "        continue\n",
    "\n",
    "    entry = candle['high'].max() + 0.05  # buffer\n",
    "    sl = candle['low'].min()\n",
    "    target = entry + 1.5 * (entry - sl)\n",
    "\n",
    "    # Track trade intraday\n",
    "    day_data = next_day_data[next_day_data['timestamp'].dt.time >= pd.to_datetime(\"09:30\").time()]\n",
    "    entry_hit = day_data[day_data['high'] >= entry]\n",
    "\n",
    "    if entry_hit.empty:\n",
    "        continue  # trade not triggered\n",
    "\n",
    "    entry_time = entry_hit.iloc[0]['timestamp']\n",
    "    trade_data = day_data[day_data['timestamp'] >= entry_time]\n",
    "\n",
    "    # SL/Target check\n",
    "    hit_price = None\n",
    "    exit_time = None\n",
    "    result = \"Time Exit\"\n",
    "    for _, r in trade_data.iterrows():\n",
    "        if r['low'] <= sl:\n",
    "            hit_price = sl\n",
    "            exit_time = r['timestamp']\n",
    "            result = \"SL\"\n",
    "            break\n",
    "        elif r['high'] >= target:\n",
    "            hit_price = target\n",
    "            exit_time = r['timestamp']\n",
    "            result = \"Target\"\n",
    "            break\n",
    "\n",
    "    if not hit_price:\n",
    "        # Time exit at 3:20\n",
    "        exit_row = trade_data[trade_data['timestamp'].dt.time <= pd.to_datetime(\"15:20\").time()].iloc[-1]\n",
    "        hit_price = exit_row['close']\n",
    "        exit_time = exit_row['timestamp']\n",
    "\n",
    "    pnl = hit_price - entry\n",
    "\n",
    "    results.append({\n",
    "        'symbol': symbol,\n",
    "        'signal_date': signal_date,\n",
    "        'entry_date': next_day,\n",
    "        'entry_time': entry_time,\n",
    "        'entry_price': entry,\n",
    "        'exit_price': hit_price,\n",
    "        'exit_time': exit_time,\n",
    "        'result': result,\n",
    "        'pnl': pnl\n",
    "    })\n",
    "\n",
    "print(f\"Number of trades: {len(results)}\")\n",
    "if results:\n",
    "    print(\"Keys in first trade dict:\", results[0].keys())\n",
    "else:\n",
    "    print(\"âš  No trades generated â€” conditions likely too strict.\")\n",
    "\n",
    "\n",
    "# --- STEP 4: Backtest Summary ---\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "if not results_df.empty and 'pnl' in results_df.columns:\n",
    "    results_df['cumulative_pnl'] = results_df['pnl'].cumsum()\n",
    "    print(\"Total Trades:\", len(results_df))\n",
    "    print(\"Win Rate:\", (results_df['result'] == 'Target').mean())\n",
    "    print(\"Total PnL:\", results_df['pnl'].sum())\n",
    "else:\n",
    "    print(\"No trades generated â€” backtest summary skipped.\")\n",
    "\n",
    "\n",
    "print(\"Total Trades:\", len(results_df))\n",
    "print(\"Total PnL:\", results_df['pnl'].sum())\n",
    "print(f\"Number of trades found: {len(results)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b2a798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2388\\1869106972.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df['rsi'] = df.groupby('symbol', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš  No trades generated â€” even with relaxed filters. Check data formatting or symbol names.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import ta  # lightweight technical analysis library (no TA-Lib headaches)\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: LOAD & PREPARE DATA\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"all_stocks_ohlc.csv\", parse_dates=['timestamp'])\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "df.sort_values(by=['symbol', 'timestamp'], inplace=True)\n",
    "\n",
    "# Add RSI (14) using 'ta' library\n",
    "df['rsi'] = df.groupby('symbol', group_keys=False).apply(\n",
    "    lambda x: ta.momentum.RSIIndicator(x['close'], window=14).rsi()\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Extract date/time columns\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['time'] = df['timestamp'].dt.time\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: DAILY AGGREGATIONS\n",
    "# ----------------------------\n",
    "daily = df.groupby(['symbol', 'date']).agg({\n",
    "    'open': 'first',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last',\n",
    "    'volume': 'sum',\n",
    "}).reset_index()\n",
    "\n",
    "# Previous day high\n",
    "daily['prev_day_high'] = daily.groupby('symbol')['high'].shift(1)\n",
    "\n",
    "# Weekly high (rolling 5 trading days)\n",
    "daily['weekly_high'] = daily.groupby('symbol')['high'].rolling(window=5, min_periods=1).max().reset_index(level=0, drop=True)\n",
    "\n",
    "# Average 5-day volume\n",
    "daily['avg_5_vol'] = daily.groupby('symbol')['volume'].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: RELAXED SIGNAL LOGIC\n",
    "# ----------------------------\n",
    "# Relaxed conditions to ensure trades occur for testing\n",
    "daily['cond1'] = daily['volume'] > 1.05 * daily['avg_5_vol']  # smaller multiplier\n",
    "daily['cond2'] = daily['close'] >= daily['prev_day_high']     # allow equal to\n",
    "daily['cond3'] = daily['close'] >= daily['weekly_high']       # allow equal to\n",
    "daily['cond4'] = True  # ignore RSI for testing\n",
    "\n",
    "# Final signal = all relaxed conditions\n",
    "daily['final_signal'] = daily['cond1'] & daily['cond2'] & daily['cond3'] & daily['cond4']\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: NEXT-DAY TRADE EXECUTION\n",
    "# ----------------------------\n",
    "results = []\n",
    "\n",
    "for idx, row in daily.iterrows():\n",
    "    if not row['final_signal']:\n",
    "        continue\n",
    "\n",
    "    symbol = row['symbol']\n",
    "    signal_date = pd.to_datetime(row['date'])\n",
    "    next_day = signal_date + timedelta(days=1)\n",
    "\n",
    "    # Get next day's 5-min data\n",
    "    next_day_data = df[(df['symbol'] == symbol) & (df['timestamp'].dt.date == next_day.date())]\n",
    "    if next_day_data.empty:\n",
    "        continue\n",
    "\n",
    "    # First 15-min candle\n",
    "    candle = next_day_data[\n",
    "        (next_day_data['timestamp'].dt.time >= pd.to_datetime(\"09:15\").time()) &\n",
    "        (next_day_data['timestamp'].dt.time <= pd.to_datetime(\"09:30\").time())\n",
    "    ]\n",
    "    if candle.empty:\n",
    "        continue\n",
    "\n",
    "    entry = candle['high'].max() + 0.05  # buffer\n",
    "    sl = candle['low'].min()\n",
    "    target = entry + 1.5 * (entry - sl)\n",
    "\n",
    "    # Track intraday after 9:30\n",
    "    day_data = next_day_data[next_day_data['timestamp'].dt.time >= pd.to_datetime(\"09:30\").time()]\n",
    "    entry_hit = day_data.iloc[[0]]\n",
    "    entry_time = entry_hit.iloc[0]['timestamp']\n",
    "    trade_data = day_data[day_data['timestamp'] >= entry_time]\n",
    "\n",
    "    # Determine exit\n",
    "    hit_price = None\n",
    "    exit_time = None\n",
    "    result = \"Time Exit\"\n",
    "\n",
    "    for _, r in trade_data.iterrows():\n",
    "        if r['low'] <= sl:\n",
    "            hit_price = sl\n",
    "            exit_time = r['timestamp']\n",
    "            result = \"SL\"\n",
    "            break\n",
    "        elif r['high'] >= target:\n",
    "            hit_price = target\n",
    "            exit_time = r['timestamp']\n",
    "            result = \"Target\"\n",
    "            break\n",
    "\n",
    "    if hit_price is None:\n",
    "        # Exit at 3:20 PM\n",
    "        exit_rows = trade_data[trade_data['timestamp'].dt.time <= pd.to_datetime(\"15:20\").time()]\n",
    "        if exit_rows.empty:\n",
    "            continue\n",
    "        exit_row = exit_rows.iloc[-1]\n",
    "        hit_price = exit_row['close']\n",
    "        exit_time = exit_row['timestamp']\n",
    "\n",
    "    pnl = hit_price - entry\n",
    "\n",
    "    results.append({\n",
    "        'symbol': symbol,\n",
    "        'signal_date': signal_date,\n",
    "        'entry_date': next_day,\n",
    "        'entry_time': entry_time,\n",
    "        'entry_price': entry,\n",
    "        'exit_price': hit_price,\n",
    "        'exit_time': exit_time,\n",
    "        'result': result,\n",
    "        'pnl': pnl\n",
    "    })\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: BACKTEST SUMMARY\n",
    "# ----------------------------\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "if not results_df.empty:\n",
    "    results_df['cumulative_pnl'] = results_df['pnl'].cumsum()\n",
    "    print(\"âœ… Backtest Complete\")\n",
    "    print(\"Total Trades:\", len(results_df))\n",
    "    print(\"Win Rate:\", (results_df['result'] == 'Target').mean())\n",
    "    print(\"Total PnL:\", results_df['pnl'].sum())\n",
    "    results_df.to_csv(\"backtest_results.csv\", index=False)\n",
    "else:\n",
    "    print(\"âš  No trades generated â€” even with relaxed filters. Check data formatting or symbol names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f66371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2388\\589687931.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(SYMBOL_COL, group_keys=False).apply(compute_rsi).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signals found: 0\n",
      "No trades executed (signals may be zero or next-day data missing).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import time, timedelta\n",
    "import ta\n",
    "\n",
    "# --------- CONFIG ----------\n",
    "CSV_FILE = \"all_stocks_ohlc.csv\"   # change path if needed\n",
    "TIMESTAMP_COL = \"timestamp\"\n",
    "SYMBOL_COL = \"symbol\"              # change if your symbol column named differently\n",
    "# Trading times (5-min candles)\n",
    "SIGNAL_CANDLE_TIME = time(15, 15)  # signal evaluated at 15:15 candle close\n",
    "ENTRY_CANDLE_TIME = time(9, 30)    # entry at close of 09:30 candle next day\n",
    "SQUARE_OFF_TIME = time(15, 20)     # force exit at or before 15:20\n",
    "RSI_PERIOD = 14\n",
    "WEEK_LOOKBACK = 5                  # \"last week high\" ~ last 5 trading days\n",
    "VOL_LOOKBACK = 5                   # avg over past 5 trading days\n",
    "RISK_REWARD = 1.5\n",
    "\n",
    "# --------- LOAD & PREP ----------\n",
    "df = pd.read_csv(CSV_FILE, parse_dates=[TIMESTAMP_COL])\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "\n",
    "# If symbol column not present try guess\n",
    "if SYMBOL_COL not in df.columns:\n",
    "    possible = [c for c in df.columns if c not in ['timestamp','open','high','low','close','volume','openinterest']]\n",
    "    if possible:\n",
    "        SYMBOL_COL = possible[0]\n",
    "    else:\n",
    "        raise KeyError(\"Symbol column not found. Please ensure a 'symbol' column exists in CSV.\")\n",
    "\n",
    "# ensure sorted within each symbol\n",
    "df.sort_values([SYMBOL_COL, TIMESTAMP_COL], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# add date/time helpers\n",
    "df['date'] = df[TIMESTAMP_COL].dt.date\n",
    "df['time'] = df[TIMESTAMP_COL].dt.time\n",
    "\n",
    "# --------- RSI per symbol (on 5-min series) ----------\n",
    "def compute_rsi(group):\n",
    "    rsi = ta.momentum.RSIIndicator(close=group['close'], window=RSI_PERIOD).rsi()\n",
    "    group = group.assign(rsi=rsi.values)\n",
    "    return group\n",
    "\n",
    "df = df.groupby(SYMBOL_COL, group_keys=False).apply(compute_rsi).reset_index(drop=True)\n",
    "\n",
    "# --------- Prepare daily aggregates (per symbol) ----------\n",
    "# daily total volume, daily high, etc.\n",
    "daily = df.groupby([SYMBOL_COL, 'date']).agg(\n",
    "    day_open = ('open','first'),\n",
    "    day_high = ('high','max'),\n",
    "    day_low = ('low','min'),\n",
    "    day_close = ('close','last'),\n",
    "    day_volume = ('volume','sum')\n",
    ").reset_index()\n",
    "\n",
    "# previous day high and rolling weekly high (last 5 trading days)\n",
    "daily['prev_day_high'] = daily.groupby(SYMBOL_COL)['day_high'].shift(1)\n",
    "daily['weekly_high'] = daily.groupby(SYMBOL_COL)['day_high'].rolling(window=WEEK_LOOKBACK, min_periods=1).max().reset_index(level=0, drop=True)\n",
    "daily['avg_5day_vol'] = daily.groupby(SYMBOL_COL)['day_volume'].rolling(window=VOL_LOOKBACK, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# --------- Build mapping for quick intraday lookup ----------\n",
    "# We'll need to quickly get:\n",
    "# - the 15:15 candle row for a given symbol & date\n",
    "# - the next day's 09:30 candle close (entry)\n",
    "# - intraday series for next day after entry\n",
    "# Build group dicts for faster access\n",
    "symbol_groups = {sym: g.reset_index(drop=True) for sym, g in df.groupby(SYMBOL_COL)}\n",
    "\n",
    "# --------- SIGNAL GENERATION (based on 15:15 candle) ----------\n",
    "signals = []  # list of dicts with symbol and signal_date\n",
    "\n",
    "for idx, dr in daily.iterrows():\n",
    "    sym = dr[SYMBOL_COL]\n",
    "    cur_date = dr['date']\n",
    "\n",
    "    # locate that symbol's intraday data\n",
    "    intraday = symbol_groups.get(sym)\n",
    "    if intraday is None:\n",
    "        continue\n",
    "\n",
    "    # get all rows for that date\n",
    "    day_rows = intraday[intraday['date'] == cur_date]\n",
    "    if day_rows.empty:\n",
    "        continue\n",
    "\n",
    "    # total volume today already in daily['day_volume']\n",
    "    today_total_vol = dr['day_volume']\n",
    "    avg_5_vol = dr['avg_5day_vol'] if not pd.isna(dr['avg_5day_vol']) else np.nan\n",
    "\n",
    "    # Volume condition: today_total_vol > 1.0 * avg_5_vol\n",
    "    cond_vol = False\n",
    "    if not np.isnan(avg_5_vol):\n",
    "        cond_vol = (today_total_vol > 1.0 * avg_5_vol)\n",
    "\n",
    "    # get 15:15 candle row\n",
    "    candle_1515 = day_rows[day_rows['time'] == SIGNAL_CANDLE_TIME]\n",
    "    if candle_1515.empty:\n",
    "        # no 15:15 candle â€” skip\n",
    "        continue\n",
    "    candle_1515 = candle_1515.iloc[-1]  # should be single row\n",
    "\n",
    "    # Price conditions\n",
    "    cond_prev_high = False\n",
    "    if not pd.isna(dr['prev_day_high']):\n",
    "        cond_prev_high = (candle_1515['close'] > dr['prev_day_high'])\n",
    "\n",
    "    cond_week_high = False\n",
    "    if not pd.isna(dr['weekly_high']):\n",
    "        cond_week_high = (candle_1515['close'] > dr['weekly_high'])\n",
    "\n",
    "    # RSI condition: check cross above 70 at 15:15\n",
    "    # Need previous rsi value in same day (or the last available prior index)\n",
    "    # We'll find previous row in intraday before this timestamp\n",
    "    idx_c = candle_1515.name  # original index in the intraday group\n",
    "    # but since we used .iloc above, we don't have direct positional index; instead compute via timestamp\n",
    "    ts = candle_1515[TIMESTAMP_COL]\n",
    "    prev_rows = day_rows[day_rows[TIMESTAMP_COL] < ts]\n",
    "    cond_rsi = False\n",
    "    if 'rsi' in candle_1515.index:\n",
    "        rsi_now = candle_1515['rsi']\n",
    "        rsi_prev = prev_rows['rsi'].iloc[-1] if not prev_rows.empty else np.nan\n",
    "        # require prev RSI <= 70 and current RSI > 70 (cross above)\n",
    "        if (not np.isnan(rsi_now)) and (not np.isnan(rsi_prev)):\n",
    "            cond_rsi = (rsi_prev <= 70) and (rsi_now > 70)\n",
    "        else:\n",
    "            # fallback: require rsi_now > 70\n",
    "            cond_rsi = (not np.isnan(rsi_now)) and (rsi_now > 70)\n",
    "\n",
    "    # final signal: all conditions must be True\n",
    "    if cond_vol and cond_prev_high and cond_week_high and cond_rsi:\n",
    "        signals.append({\n",
    "            'symbol': sym,\n",
    "            'signal_date': cur_date,\n",
    "            'signal_timestamp': candle_1515[TIMESTAMP_COL],\n",
    "            'candle_close_1515': candle_1515['close'],\n",
    "            'today_total_vol': today_total_vol,\n",
    "            'avg_5day_vol': avg_5_vol,\n",
    "            'rsi_prev': float(rsi_prev) if 'rsi_prev' in locals() else None,\n",
    "            'rsi_now': float(rsi_now) if 'rsi_now' in locals() else None\n",
    "        })\n",
    "\n",
    "# Debug: how many signals found\n",
    "print(f\"Signals found: {len(signals)}\")\n",
    "\n",
    "# --------- EXECUTE NEXT-DAY TRADES ----------\n",
    "trades = []\n",
    "for s in signals:\n",
    "    sym = s['symbol']\n",
    "    sig_date = pd.to_datetime(s['signal_date'])\n",
    "    entry_date = (sig_date + timedelta(days=1)).date()\n",
    "\n",
    "    intraday = symbol_groups.get(sym)\n",
    "    if intraday is None:\n",
    "        continue\n",
    "\n",
    "    next_day_rows = intraday[intraday['date'] == entry_date]\n",
    "    if next_day_rows.empty:\n",
    "        # no next day data (holiday or missing) â€” skip\n",
    "        continue\n",
    "\n",
    "    # find the 09:30 candle (entry candle) for next day\n",
    "    entry_candle = next_day_rows[next_day_rows['time'] == ENTRY_CANDLE_TIME]\n",
    "    if entry_candle.empty:\n",
    "        # no 09:30 candle â€” fallback to first available candle after 09:30\n",
    "        entry_candle = next_day_rows[next_day_rows['time'] > ENTRY_CANDLE_TIME]\n",
    "        if entry_candle.empty:\n",
    "            # fallback to first candle of the day\n",
    "            entry_candle = next_day_rows.iloc[[0]]\n",
    "    entry_candle = entry_candle.iloc[0]\n",
    "\n",
    "    entry_price = float(entry_candle['close'])\n",
    "    sl = float(entry_candle['low'])\n",
    "    target = entry_price + RISK_REWARD * (entry_price - sl)\n",
    "\n",
    "    # Build the trade_data: all intraday rows for that next day after entry_time (inclusive)\n",
    "    trade_after = next_day_rows[next_day_rows[TIMESTAMP_COL] >= entry_candle[TIMESTAMP_COL]].copy()\n",
    "    if trade_after.empty:\n",
    "        continue\n",
    "\n",
    "    exit_price = None\n",
    "    exit_time = None\n",
    "    exit_type = \"Time Exit\"\n",
    "\n",
    "    # iterate rows to see if SL or Target hit\n",
    "    for _, r in trade_after.iterrows():\n",
    "        if r['low'] <= sl:\n",
    "            exit_price = sl\n",
    "            exit_time = r[TIMESTAMP_COL]\n",
    "            exit_type = \"SL\"\n",
    "            break\n",
    "        if r['high'] >= target:\n",
    "            exit_price = target\n",
    "            exit_time = r[TIMESTAMP_COL]\n",
    "            exit_type = \"Target\"\n",
    "            break\n",
    "\n",
    "    # If none hit, force exit at last available bar <= SQUARE_OFF_TIME\n",
    "    if exit_price is None:\n",
    "        candidates = trade_after[trade_after['time'] <= SQUARE_OFF_TIME]\n",
    "        if not candidates.empty:\n",
    "            last_row = candidates.iloc[-1]\n",
    "        else:\n",
    "            # fallback to last available row of that day\n",
    "            last_row = trade_after.iloc[-1]\n",
    "        exit_price = float(last_row['close'])\n",
    "        exit_time = last_row[TIMESTAMP_COL]\n",
    "        exit_type = \"Time Exit\"\n",
    "\n",
    "    pnl = exit_price - entry_price\n",
    "\n",
    "    trades.append({\n",
    "        'symbol': sym,\n",
    "        'signal_date': s['signal_date'],\n",
    "        'entry_date': entry_date,\n",
    "        'entry_time': entry_candle[TIMESTAMP_COL],\n",
    "        'entry_price': entry_price,\n",
    "        'exit_time': exit_time,\n",
    "        'exit_price': exit_price,\n",
    "        'exit_type': exit_type,\n",
    "        'pnl': pnl\n",
    "    })\n",
    "\n",
    "# --------- SUMMARY ----------\n",
    "trades_df = pd.DataFrame(trades)\n",
    "if trades_df.empty:\n",
    "    print(\"No trades executed (signals may be zero or next-day data missing).\")\n",
    "else:\n",
    "    trades_df['cumulative_pnl'] = trades_df['pnl'].cumsum()\n",
    "    wins = trades_df['exit_type'] == 'Target'\n",
    "    print(\"Total trades:\", len(trades_df))\n",
    "    print(\"Wins (target hit):\", wins.sum())\n",
    "    print(\"Win rate:\", wins.mean())\n",
    "    print(\"Total PnL:\", trades_df['pnl'].sum())\n",
    "    print(\"\\nSample trades:\")\n",
    "    print(trades_df.head().to_string(index=False))\n",
    "\n",
    "    # save results\n",
    "    trades_df.to_csv(\"backtest_trades_exact_1515_to_0930.csv\", index=False)\n",
    "    print(\"Saved trades to backtest_trades_exact_1515_to_0930.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11497a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ COMPLETE Canon Momentum Strategy - ENTIRE CSV Analysis\n",
      "======================================================================\n",
      "ðŸ“Š COMPLETE DATASET ANALYSIS:\n",
      "Total rows in CSV: 57,375\n",
      "Total stocks: 51\n",
      "Total trading dates: 45\n",
      "Date range: 2025-05-26 to 2025-07-25\n",
      "Period: 61 calendar days\n",
      "\n",
      "ðŸ“ˆ ANALYSIS PERIOD (No Trading): 2025-05-26 to 2025-05-30 (5 days)\n",
      "ðŸŽ¯ TRADING PERIOD: 2025-06-02 to 2025-07-25 (40 days)\n",
      "\n",
      "ðŸ“Š Building Volume History for ALL 51 Stocks...\n",
      "âœ… Volume baseline calculated for 51 stocks\n",
      "Stocks ready for trading: ['ADANIENT', 'ADANIPORTS', 'APOLLOHOSP', 'ASIANPAINT', 'AXISBANK', 'BAJAJ-AUTO', 'BAJAJFINSV', 'BAJFINANCE', 'BEL', 'BHARTIARTL']...\n",
      "\n",
      "ðŸŽ¯ ANALYZING ALL 40 TRADING DAYS...\n",
      "======================================================================\n",
      "ðŸ“… Processing Day 5/40: 2025-06-06\n",
      "ðŸ“… Processing Day 10/40: 2025-06-13\n",
      "ðŸ“… Processing Day 15/40: 2025-06-20\n",
      "ðŸ“… Processing Day 20/40: 2025-06-27\n",
      "ðŸ“… Processing Day 25/40: 2025-07-04\n",
      "ðŸ“… Processing Day 30/40: 2025-07-11\n",
      "ðŸ“… Processing Day 35/40: 2025-07-18\n",
      "ðŸ“… Processing Day 40/40: 2025-07-25\n",
      "\n",
      "ðŸ† COMPLETE STRATEGY PERFORMANCE SUMMARY\n",
      "======================================================================\n",
      "ðŸ“Š COMPLETE ANALYSIS RESULTS:\n",
      "Analysis Period: 2025-05-26 to 2025-05-30 (5 days)\n",
      "Trading Period: 2025-06-02 to 2025-07-25 (40 days)\n",
      "Total Trading Days Analyzed: 40\n",
      "\n",
      "ðŸ“ˆ TRADING STATISTICS:\n",
      "Total Momentum Setups: 254\n",
      "Actual Trades Executed: 138\n",
      "Winning Trades: 68\n",
      "Losing Trades: 70\n",
      "Win Rate: 49.3%\n",
      "Average Profit: 0.69%\n",
      "Average Loss: -0.69%\n",
      "Total P&L: -1.49%\n",
      "Average P&L per Trade: -0.01%\n",
      "\n",
      "ðŸ† TOP PERFORMING STOCKS:\n",
      "            Trades  Total_PnL  Avg_PnL\n",
      "symbol                                \n",
      "JIOFIN           5       3.35     0.67\n",
      "TECHM            6       2.91     0.48\n",
      "HCLTECH          3       2.28     0.76\n",
      "ASIANPAINT       7       1.56     0.22\n",
      "HDFCBANK         5       1.43     0.29\n",
      "GRASIM           6       1.43     0.24\n",
      "HINDUNILVR       5       1.38     0.28\n",
      "BEL              7       1.33     0.19\n",
      "INFY             4       0.94     0.23\n",
      "EICHERMOT        4       0.88     0.22\n",
      "\n",
      "ðŸ“… WEEKLY P&L:\n",
      "Week 23 (2025-06-02 to 2025-06-06): +0.37%\n",
      "Week 24 (2025-06-09 to 2025-06-13): +9.18%\n",
      "Week 25 (2025-06-17 to 2025-06-20): -3.41%\n",
      "Week 26 (2025-06-23 to 2025-06-27): +7.40%\n",
      "Week 27 (2025-06-30 to 2025-07-04): -6.55%\n",
      "Week 28 (2025-07-07 to 2025-07-11): -1.11%\n",
      "Week 29 (2025-07-14 to 2025-07-18): -3.32%\n",
      "Week 30 (2025-07-21 to 2025-07-25): -4.05%\n",
      "\n",
      "ðŸ’¾ SAVING ANALYSIS TO CSV FILES...\n",
      "âœ… Saved: momentum_strategy_complete_results.csv (254 rows)\n",
      "âœ… Saved: momentum_strategy_daily_summary.csv (40 rows)\n",
      "âœ… Saved: momentum_strategy_stock_performance.csv (51 stocks)\n",
      "âœ… Saved: momentum_strategy_volume_baseline.csv (51 stocks)\n",
      "âœ… Saved: momentum_strategy_detailed_trades.csv (sample of 100 trades)\n",
      "âœ… Saved: momentum_strategy_analysis_summary.csv\n",
      "\n",
      "ðŸ“ ALL CSV FILES CREATED:\n",
      "1. momentum_strategy_complete_results.csv - All individual trades\n",
      "2. momentum_strategy_daily_summary.csv - Daily performance\n",
      "3. momentum_strategy_stock_performance.csv - Stock-wise results\n",
      "4. momentum_strategy_volume_baseline.csv - 5-day volume data\n",
      "5. momentum_strategy_detailed_trades.csv - Sample detailed trades\n",
      "6. momentum_strategy_analysis_summary.csv - Analysis overview\n",
      "\n",
      "âœ… COMPLETE CSV ANALYSIS FINISHED!\n",
      "ðŸŽ¯ Analyzed 57,375 rows across 40 trading days\n",
      "ðŸ’¾ All results saved to CSV files in current directory\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load data\n",
    "file = 'all_stocks_ohlc.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Convert timestamp and prepare data\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "df['time'] = df['timestamp'].dt.time\n",
    "df = df.sort_values(['symbol', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "print(\"ðŸš€ COMPLETE Canon Momentum Strategy - ENTIRE CSV Analysis\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get ALL unique trading dates from CSV\n",
    "unique_dates = sorted(df['date'].unique())\n",
    "total_dates = len(unique_dates)\n",
    "\n",
    "print(f\"ðŸ“Š COMPLETE DATASET ANALYSIS:\")\n",
    "print(f\"Total rows in CSV: {len(df):,}\")\n",
    "print(f\"Total stocks: {df['symbol'].nunique()}\")\n",
    "print(f\"Total trading dates: {total_dates}\")\n",
    "print(f\"Date range: {unique_dates[0]} to {unique_dates[-1]}\")\n",
    "print(f\"Period: {(pd.to_datetime(unique_dates[-1]) - pd.to_datetime(unique_dates[0])).days + 1} calendar days\")\n",
    "\n",
    "# Verify we have enough data\n",
    "if total_dates < 6:\n",
    "    print(\"âŒ Need at least 6 days of data (5 for analysis + 1 for trading)\")\n",
    "    exit()\n",
    "\n",
    "# Split into analysis and trading periods\n",
    "analysis_days = unique_dates[:5]  # First 5 days for volume analysis\n",
    "trading_days = unique_dates[5:]   # ALL remaining days for trading\n",
    "\n",
    "print(f\"\\nðŸ“ˆ ANALYSIS PERIOD (No Trading): {analysis_days[0]} to {analysis_days[-1]} ({len(analysis_days)} days)\")\n",
    "print(f\"ðŸŽ¯ TRADING PERIOD: {trading_days[0]} to {trading_days[-1]} ({len(trading_days)} days)\")\n",
    "\n",
    "# Build 5-day volume baseline for ALL stocks\n",
    "print(f\"\\nðŸ“Š Building Volume History for ALL {df['symbol'].nunique()} Stocks...\")\n",
    "\n",
    "daily_volumes = {}\n",
    "stocks_with_data = []\n",
    "\n",
    "for symbol in df['symbol'].unique():\n",
    "    symbol_data = df[df['symbol'] == symbol]\n",
    "    \n",
    "    # Calculate daily volumes for analysis period\n",
    "    daily_vol = []\n",
    "    for date in analysis_days:\n",
    "        day_data = symbol_data[symbol_data['date'] == date]\n",
    "        if len(day_data) > 0:\n",
    "            total_volume = day_data['volume'].sum()\n",
    "            daily_vol.append(total_volume)\n",
    "        else:\n",
    "            daily_vol.append(0)\n",
    "    \n",
    "    # Only include stocks with data in all 5 analysis days\n",
    "    if sum(daily_vol) > 0 and len([v for v in daily_vol if v > 0]) >= 3:  # At least 3 days of data\n",
    "        daily_volumes[symbol] = daily_vol\n",
    "        stocks_with_data.append(symbol)\n",
    "\n",
    "print(f\"âœ… Volume baseline calculated for {len(stocks_with_data)} stocks\")\n",
    "print(f\"Stocks ready for trading: {stocks_with_data[:10]}{'...' if len(stocks_with_data) > 10 else ''}\")\n",
    "\n",
    "# Momentum calculation function\n",
    "def calculate_momentum_signals(df_symbol, analysis_volumes):\n",
    "    \"\"\"Calculate 4 momentum indicators for a symbol\"\"\"\n",
    "    df_symbol = df_symbol.copy()\n",
    "    \n",
    "    # RSI calculation (14 period)\n",
    "    def calculate_rsi(prices, period=14):\n",
    "        delta = prices.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "    \n",
    "    df_symbol['rsi'] = calculate_rsi(df_symbol['close'])\n",
    "    df_symbol['rsi_signal'] = df_symbol['rsi'] > 70\n",
    "    \n",
    "    # Daily aggregations\n",
    "    daily_data = df_symbol.groupby('date').agg({\n",
    "        'high': 'max',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum'\n",
    "    })\n",
    "    \n",
    "    # Volume signal: today > 1.5x average of analysis period\n",
    "    avg_volume_5d = np.mean(analysis_volumes) if len(analysis_volumes) > 0 else 0\n",
    "    daily_data['volume_signal'] = daily_data['volume'] > (1 * avg_volume_5d)\n",
    "    \n",
    "    # Price signals\n",
    "    daily_data['prev_high'] = daily_data['high'].shift(1)\n",
    "    daily_data['close_above_prev_high'] = daily_data['close'] > daily_data['prev_high']\n",
    "    \n",
    "    daily_data['week_high_5d'] = daily_data['high'].rolling(window=5).max().shift(1)\n",
    "    daily_data['close_above_week_high'] = daily_data['close'] > daily_data['week_high_5d']\n",
    "    \n",
    "    # Map back to intraday data\n",
    "    date_mappings = {\n",
    "        'volume_signal': daily_data['volume_signal'].to_dict(),\n",
    "        'close_above_prev_high': daily_data['close_above_prev_high'].to_dict(),\n",
    "        'close_above_week_high': daily_data['close_above_week_high'].to_dict()\n",
    "    }\n",
    "    \n",
    "    for signal, mapping in date_mappings.items():\n",
    "        df_symbol[signal] = df_symbol['date'].map(mapping)\n",
    "    \n",
    "    # Count signals (need 3+ out of 4)\n",
    "    df_symbol['signal_count'] = (\n",
    "        df_symbol['volume_signal'].fillna(False).astype(int) +\n",
    "        df_symbol['rsi_signal'].fillna(False).astype(int) +\n",
    "        df_symbol['close_above_prev_high'].fillna(False).astype(int) +\n",
    "        df_symbol['close_above_week_high'].fillna(False).astype(int)\n",
    "    )\n",
    "    \n",
    "    df_symbol['bullish_momentum'] = df_symbol['signal_count'] >= 3\n",
    "    \n",
    "    return df_symbol\n",
    "\n",
    "# ANALYZE ALL TRADING DAYS\n",
    "print(f\"\\nðŸŽ¯ ANALYZING ALL {len(trading_days)} TRADING DAYS...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "all_trading_results = []\n",
    "daily_summary = []\n",
    "\n",
    "for day_num, target_date in enumerate(trading_days, 1):\n",
    "    \n",
    "    # Show progress every 5 days\n",
    "    if day_num % 5 == 0 or day_num == len(trading_days):\n",
    "        print(f\"ðŸ“… Processing Day {day_num}/{len(trading_days)}: {target_date}\")\n",
    "    \n",
    "    # Get data for this trading day\n",
    "    day_data = df[df['date'] == target_date].copy()\n",
    "    \n",
    "    if len(day_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Find momentum stocks for this day\n",
    "    momentum_stocks = []\n",
    "    \n",
    "    for symbol in stocks_with_data:\n",
    "        if symbol not in day_data['symbol'].values:\n",
    "            continue\n",
    "            \n",
    "        # Get historical data up to previous day\n",
    "        prev_dates = unique_dates[:unique_dates.index(target_date)]\n",
    "        symbol_hist_data = df[\n",
    "            (df['symbol'] == symbol) & \n",
    "            (df['date'].isin(prev_dates))\n",
    "        ].copy()\n",
    "        \n",
    "        if len(symbol_hist_data) < 10:  # Need minimum data\n",
    "            continue\n",
    "            \n",
    "        # Calculate momentum signals\n",
    "        try:\n",
    "            symbol_with_signals = calculate_momentum_signals(symbol_hist_data, daily_volumes[symbol])\n",
    "            \n",
    "            # Check if previous day showed momentum\n",
    "            if len(prev_dates) > 0:\n",
    "                last_day_data = symbol_with_signals[symbol_with_signals['date'] == prev_dates[-1]]\n",
    "                if len(last_day_data) > 0 and last_day_data['bullish_momentum'].any():\n",
    "                    momentum_stocks.append(symbol)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Execute trades for momentum stocks\n",
    "    day_trades = 0\n",
    "    day_setups = 0\n",
    "    day_pnl = 0\n",
    "    \n",
    "    for stock in momentum_stocks:\n",
    "        stock_day_data = day_data[day_data['symbol'] == stock].copy()\n",
    "        if len(stock_day_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        day_setups += 1\n",
    "        \n",
    "        # Trading setup\n",
    "        first_candle = stock_day_data.iloc[0]\n",
    "        entry_price = first_candle['high'] + 0.10\n",
    "        stop_loss = entry_price * 0.98  # 2% stop loss\n",
    "        target = entry_price + ((entry_price - stop_loss) * 1.5)  # 1:1.5 ratio\n",
    "        \n",
    "        # Check execution\n",
    "        day_high = stock_day_data['high'].max()\n",
    "        day_low = stock_day_data['low'].min()\n",
    "        \n",
    "        if day_high >= entry_price:  # Trade triggered\n",
    "            day_trades += 1\n",
    "            \n",
    "            if day_high >= target:\n",
    "                outcome = \"TARGET\"\n",
    "                pnl = target - entry_price\n",
    "            elif day_low <= stop_loss:\n",
    "                outcome = \"STOP_LOSS\"\n",
    "                pnl = stop_loss - entry_price\n",
    "            else:\n",
    "                outcome = \"SQUARE_OFF\"\n",
    "                pnl = stock_day_data.iloc[-1]['close'] - entry_price\n",
    "        else:\n",
    "            outcome = \"NO_ENTRY\"\n",
    "            pnl = 0\n",
    "        \n",
    "        pnl_pct = (pnl / entry_price) * 100 if entry_price > 0 else 0\n",
    "        day_pnl += pnl_pct\n",
    "        \n",
    "        all_trading_results.append({\n",
    "            'day_num': day_num,\n",
    "            'date': target_date,\n",
    "            'symbol': stock,\n",
    "            'entry': entry_price,\n",
    "            'target': target,\n",
    "            'stop_loss': stop_loss,\n",
    "            'outcome': outcome,\n",
    "            'pnl_pct': pnl_pct\n",
    "        })\n",
    "    \n",
    "    # Daily summary\n",
    "    daily_summary.append({\n",
    "        'day_num': day_num,\n",
    "        'date': target_date,\n",
    "        'momentum_stocks': len(momentum_stocks),\n",
    "        'setups': day_setups,\n",
    "        'trades': day_trades,\n",
    "        'day_pnl': day_pnl\n",
    "    })\n",
    "\n",
    "# FINAL PERFORMANCE SUMMARY\n",
    "print(f\"\\nðŸ† COMPLETE STRATEGY PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if all_trading_results:\n",
    "    results_df = pd.DataFrame(all_trading_results)\n",
    "    daily_df = pd.DataFrame(daily_summary)\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_setups = len(results_df)\n",
    "    total_trades = len(results_df[results_df['outcome'] != 'NO_ENTRY'])\n",
    "    winning_trades = len(results_df[results_df['pnl_pct'] > 0])\n",
    "    losing_trades = len(results_df[results_df['pnl_pct'] < 0])\n",
    "    \n",
    "    print(f\"ðŸ“Š COMPLETE ANALYSIS RESULTS:\")\n",
    "    print(f\"Analysis Period: {analysis_days[0]} to {analysis_days[-1]} ({len(analysis_days)} days)\")\n",
    "    print(f\"Trading Period: {trading_days[0]} to {trading_days[-1]} ({len(trading_days)} days)\")\n",
    "    print(f\"Total Trading Days Analyzed: {len(trading_days)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ TRADING STATISTICS:\")\n",
    "    print(f\"Total Momentum Setups: {total_setups}\")\n",
    "    print(f\"Actual Trades Executed: {total_trades}\")\n",
    "    print(f\"Winning Trades: {winning_trades}\")\n",
    "    print(f\"Losing Trades: {losing_trades}\")\n",
    "    \n",
    "    if total_trades > 0:\n",
    "        win_rate = (winning_trades / total_trades) * 100\n",
    "        avg_profit = results_df[results_df['pnl_pct'] > 0]['pnl_pct'].mean() if winning_trades > 0 else 0\n",
    "        avg_loss = results_df[results_df['pnl_pct'] < 0]['pnl_pct'].mean() if losing_trades > 0 else 0\n",
    "        total_pnl = results_df['pnl_pct'].sum()\n",
    "        \n",
    "        print(f\"Win Rate: {win_rate:.1f}%\")\n",
    "        print(f\"Average Profit: {avg_profit:.2f}%\")\n",
    "        print(f\"Average Loss: {avg_loss:.2f}%\")\n",
    "        print(f\"Total P&L: {total_pnl:+.2f}%\")\n",
    "        print(f\"Average P&L per Trade: {total_pnl/total_trades:.2f}%\")\n",
    "        \n",
    "        # Best performing stocks\n",
    "        stock_performance = results_df.groupby('symbol')['pnl_pct'].agg(['count', 'sum', 'mean']).round(2)\n",
    "        stock_performance.columns = ['Trades', 'Total_PnL', 'Avg_PnL']\n",
    "        stock_performance = stock_performance.sort_values('Total_PnL', ascending=False)\n",
    "        \n",
    "        print(f\"\\nðŸ† TOP PERFORMING STOCKS:\")\n",
    "        print(stock_performance.head(10))\n",
    "        \n",
    "        # Weekly performance\n",
    "        results_df['week'] = pd.to_datetime(results_df['date']).dt.isocalendar().week\n",
    "        weekly_pnl = results_df.groupby('week')['pnl_pct'].sum().round(2)\n",
    "        \n",
    "        print(f\"\\nðŸ“… WEEKLY P&L:\")\n",
    "        for week, pnl in weekly_pnl.items():\n",
    "            week_dates = results_df[results_df['week'] == week]['date'].unique()\n",
    "            print(f\"Week {week} ({week_dates[0]} to {week_dates[-1]}): {pnl:+.2f}%\")\n",
    "\n",
    "# SAVE ALL ANALYSIS TO CSV FILES\n",
    "print(f\"\\nðŸ’¾ SAVING ANALYSIS TO CSV FILES...\")\n",
    "\n",
    "if all_trading_results:\n",
    "    # 1. Complete trading results\n",
    "    results_df = pd.DataFrame(all_trading_results)\n",
    "    results_df.to_csv('momentum_strategy_complete_results.csv', index=False)\n",
    "    print(f\"âœ… Saved: momentum_strategy_complete_results.csv ({len(results_df)} rows)\")\n",
    "    \n",
    "    # 2. Daily summary\n",
    "    daily_df = pd.DataFrame(daily_summary)\n",
    "    daily_df.to_csv('momentum_strategy_daily_summary.csv', index=False)\n",
    "    print(f\"âœ… Saved: momentum_strategy_daily_summary.csv ({len(daily_df)} rows)\")\n",
    "    \n",
    "    # 3. Stock performance summary\n",
    "    stock_performance = results_df.groupby('symbol').agg({\n",
    "        'pnl_pct': ['count', 'sum', 'mean', 'std'],\n",
    "        'outcome': lambda x: (x == 'TARGET').sum(),  # Target hits\n",
    "        'entry': 'mean'  # Average entry price\n",
    "    }).round(3)\n",
    "    \n",
    "    stock_performance.columns = ['Total_Trades', 'Total_PnL_%', 'Avg_PnL_%', 'PnL_StdDev', 'Target_Hits', 'Avg_Entry_Price']\n",
    "    stock_performance['Win_Rate_%'] = (stock_performance['Target_Hits'] / stock_performance['Total_Trades'] * 100).round(1)\n",
    "    stock_performance = stock_performance.sort_values('Total_PnL_%', ascending=False)\n",
    "    stock_performance.to_csv('momentum_strategy_stock_performance.csv')\n",
    "    print(f\"âœ… Saved: momentum_strategy_stock_performance.csv ({len(stock_performance)} stocks)\")\n",
    "\n",
    "    # 4. Volume baseline data used for analysis\n",
    " volume_baseline_df = pd.DataFrame([\n",
    " {'symbol': symbol, 'day1_volume': vols[0], 'day2_volume': vols[1], \n",
    " 'day3_volume': vols[2], 'day4_volume': vols[3], 'day5_volume': vols[4],\n",
    " 'avg_volume_5day': np.mean(vols), 'threshold_1.5x': np.mean(vols) * 1.5}\n",
    " for symbol, vols in daily_volumes.items()\n",
    " ])\n",
    " volume_baseline_df.to_csv('momentum_strategy_volume_baseline.csv', index=False)\n",
    " print(f\"âœ… Saved: momentum_strategy_volume_baseline.csv ({len(volume_baseline_df)} stocks)\")\n",
    " \n",
    " # 5. Detailed signals for each trading day (sample of first 100 records)\n",
    " if len(results_df) > 0:\n",
    " detailed_signals = []\n",
    " for _, trade in results_df.head(100).iterrows(): # Save sample for memory efficiency\n",
    " detailed_signals.append({\n",
    " 'date': trade['date'],\n",
    " 'symbol': trade['symbol'],\n",
    " 'day_num': trade['day_num'],\n",
    " 'entry_price': trade['entry'],\n",
    " 'stop_loss': trade['stop_loss'], \n",
    " 'target': trade['target'],\n",
    " 'outcome': trade['outcome'],\n",
    " 'pnl_percent': trade['pnl_pct'],\n",
    " 'risk_reward_ratio': '1:1.5'\n",
    " })\n",
    " \n",
    " detailed_df = pd.DataFrame(detailed_signals)\n",
    " detailed_df.to_csv('momentum_strategy_detailed_trades.csv', index=False)\n",
    " print(f\"âœ… Saved: momentum_strategy_detailed_trades.csv (sample of {len(detailed_df)} trades)\")\n",
    "\n",
    "# 6. Analysis period summary\n",
    "analysis_summary = {\n",
    " 'analysis_start_date': analysis_days[0],\n",
    " 'analysis_end_date': analysis_days[-1],\n",
    " 'trading_start_date': trading_days[0],\n",
    " 'trading_end_date': trading_days[-1],\n",
    " 'total_stocks_analyzed': len(stocks_with_data),\n",
    " 'total_trading_days': len(trading_days),\n",
    " 'total_rows_processed': len(df),\n",
    " 'strategy_description': 'Canon Momentum Strategy with 5-day volume baseline'\n",
    "}\n",
    "\n",
    "pd.DataFrame([analysis_summary]).to_csv('momentum_strategy_analysis_summary.csv', index=False)\n",
    "print(f\"âœ… Saved: momentum_strategy_analysis_summary.csv\")\n",
    "\n",
    "print(f\"\\nðŸ“ ALL CSV FILES CREATED:\")\n",
    "print(\"1. momentum_strategy_complete_results.csv - All individual trades\")\n",
    "print(\"2. momentum_strategy_daily_summary.csv - Daily performance\") \n",
    "print(\"3. momentum_strategy_stock_performance.csv - Stock-wise results\")\n",
    "print(\"4. momentum_strategy_volume_baseline.csv - 5-day volume data\")\n",
    "print(\"5. momentum_strategy_detailed_trades.csv - Sample detailed trades\")\n",
    "print(\"6. momentum_strategy_analysis_summary.csv - Analysis overview\")\n",
    "\n",
    "print(f\"\\nâœ… COMPLETE CSV ANALYSIS FINISHED!\")\n",
    "print(f\"ðŸŽ¯ Analyzed {len(df):,} rows across {len(trading_days)} trading days\")\n",
    "print(f\"ðŸ’¾ All results saved to CSV files in current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d77a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
